{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CPU训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "59.79554271697998\n",
      "训练次数：100，Loss：2.2845799922943115\n",
      "118.5887176990509\n",
      "训练次数：200，Loss：2.279371976852417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - USTC\\gchen\\编程\\其他\\VScode\\唐宇迪pytorch\\0_11_完整的训练流程.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     imgs, targets \u001b[39m=\u001b[39m data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     outputs \u001b[39m=\u001b[39m tudui(imgs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(outputs, targets) \u001b[39m# 计算实际输出与目标输出的差距\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m# 优化器对模型调优\u001b[39;00m\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "\u001b[1;32md:\\OneDrive - USTC\\gchen\\编程\\其他\\VScode\\唐宇迪pytorch\\0_11_完整的训练流程.ipynb Cell 2\u001b[0m in \u001b[0;36mTudui.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    118\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    393\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    394\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 395\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    396\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# from model import * 相当于把 model中的所有内容写到这里，这里直接把 model 写在这里\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 3\n",
    "\n",
    "# 添加 tensorboard\n",
    "writer = SummaryWriter(\"logs\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "            writer.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data \n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss,total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\",total_accuracy/test_data_size,total_test_step)  \n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, \"./model/tudui_{}.pth\".format(i)) # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gpu训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "time: 0.6083858013153076\n",
      "训练次数：100，Loss：2.2892918586730957\n",
      "time: 1.2415070533752441\n",
      "训练次数：200，Loss：2.2790653705596924\n",
      "time: 1.8522779941558838\n",
      "训练次数：300，Loss：2.238877296447754\n",
      "time: 2.485807180404663\n",
      "训练次数：400，Loss：2.1648778915405273\n",
      "time: 3.1150834560394287\n",
      "训练次数：500，Loss：2.0433621406555176\n",
      "time: 3.745764970779419\n",
      "训练次数：600，Loss：2.0219874382019043\n",
      "time: 4.363219261169434\n",
      "训练次数：700，Loss：2.008251190185547\n",
      "整体测试集上的Loss：313.6579860448837\n",
      "整体测试集上的正确率：0.2799000144004822\n",
      "-----第 2 轮训练开始-----\n",
      "time: 6.04424262046814\n",
      "训练次数：800，Loss：1.890910029411316\n",
      "time: 6.635796070098877\n",
      "训练次数：900，Loss：1.8351696729660034\n",
      "time: 7.2355451583862305\n",
      "训练次数：1000，Loss：1.9067059755325317\n",
      "time: 7.853265047073364\n",
      "训练次数：1100，Loss：1.9500449895858765\n",
      "time: 8.444150924682617\n",
      "训练次数：1200，Loss：1.7067413330078125\n",
      "time: 9.035863399505615\n",
      "训练次数：1300，Loss：1.6550331115722656\n",
      "time: 9.62783145904541\n",
      "训练次数：1400，Loss：1.7536404132843018\n",
      "time: 10.22350287437439\n",
      "训练次数：1500，Loss：1.8127974271774292\n",
      "整体测试集上的Loss：316.100129365921\n",
      "整体测试集上的正确率：0.28790000081062317\n",
      "-----第 3 轮训练开始-----\n",
      "time: 11.909422636032104\n",
      "训练次数：1600，Loss：1.7636224031448364\n",
      "time: 12.506839990615845\n",
      "训练次数：1700，Loss：1.6744425296783447\n",
      "time: 13.092845916748047\n",
      "训练次数：1800，Loss：1.968033790588379\n",
      "time: 13.678503036499023\n",
      "训练次数：1900，Loss：1.714121699333191\n",
      "time: 14.270248651504517\n",
      "训练次数：2000，Loss：1.9118351936340332\n",
      "time: 14.880026817321777\n",
      "训练次数：2100，Loss：1.5211042165756226\n",
      "time: 15.533589363098145\n",
      "训练次数：2200，Loss：1.5002002716064453\n",
      "time: 16.139006853103638\n",
      "训练次数：2300，Loss：1.7962427139282227\n",
      "整体测试集上的Loss：267.00492000579834\n",
      "整体测试集上的正确率：0.38600000739097595\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 定义训练的设备\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda\")   # 使用 GPU 方式一 \n",
    "#device = torch.device(\"cuda:0\") # 使用 GPU 方式二\n",
    "device = torch.device(\"dml\")\n",
    "\n",
    "# from model import * 相当于把 model中的所有内容写到这里，这里直接把 model 写在这里\n",
    "class Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Module, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "module = Module() \n",
    "module = module.to(device) # 也可以不赋值，直接 tudui.to(device) \n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "loss_fn = loss_fn.to(device) # 也可以不赋值，直接loss_fn.to(device)\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(module.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 3\n",
    "\n",
    "# 添加 tensorboard\n",
    "writer = SummaryWriter(\"logs\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    module.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        imgs, targets = data            \n",
    "        imgs = imgs.to(device) # 也可以不赋值，直接 imgs.to(device)\n",
    "        targets = targets.to(device) # 也可以不赋值，直接 targets.to(device)\n",
    "        outputs = module(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"time:\", end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "            writer.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    module.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data # 数据放到cuda上\n",
    "            imgs = imgs.to(device) # 也可以不赋值，直接 imgs.to(device)\n",
    "            targets = targets.to(device) # 也可以不赋值，直接 targets.to(device)\n",
    "            outputs = module(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.cpu().argmax(1) == targets.cpu()).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss,total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\",total_accuracy/test_data_size,total_test_step)  \n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    # torch.save(module, \"./dataset/module_{}.pth\".format(i)) # 保存每一轮训练后的结果\n",
    "    # torch.save(module.state_dict(),\"./dataset/module_{}.path\".format(i)) # 保存方式二         \n",
    "    # print(\"模型已保存\")\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e88457d6133781447915b440b258f55cb00eb78ff373bb1d13c46c34b1089a25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
