{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CPU训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "59.79554271697998\n",
      "训练次数：100，Loss：2.2845799922943115\n",
      "118.5887176990509\n",
      "训练次数：200，Loss：2.279371976852417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive - USTC\\gchen\\编程\\其他\\VScode\\唐宇迪pytorch\\0_11_完整的训练流程.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     imgs, targets \u001b[39m=\u001b[39m data\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     outputs \u001b[39m=\u001b[39m tudui(imgs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(outputs, targets) \u001b[39m# 计算实际输出与目标输出的差距\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m# 优化器对模型调优\u001b[39;00m\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "\u001b[1;32md:\\OneDrive - USTC\\gchen\\编程\\其他\\VScode\\唐宇迪pytorch\\0_11_完整的训练流程.ipynb Cell 2\u001b[0m in \u001b[0;36mTudui.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel1(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20USTC/gchen/%E7%BC%96%E7%A8%8B/%E5%85%B6%E4%BB%96/VScode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    118\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    393\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    394\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 395\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    396\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# from model import * 相当于把 model中的所有内容写到这里，这里直接把 model 写在这里\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui() \n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 3\n",
    "\n",
    "# 添加 tensorboard\n",
    "writer = SummaryWriter(\"logs\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    tudui.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "        \n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "            writer.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    tudui.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data \n",
    "            outputs = tudui(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss,total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\",total_accuracy/test_data_size,total_test_step)  \n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    torch.save(tudui, \"./model/tudui_{}.pth\".format(i)) # 保存每一轮训练后的结果\n",
    "    #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # 保存方式二         \n",
    "    print(\"模型已保存\")\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gpu训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度：50000\n",
      "测试数据集的长度：10000\n",
      "-----第 1 轮训练开始-----\n",
      "time: 1.5415096282958984\n",
      "训练次数：100，Loss：2.28582501411438\n",
      "time: 2.4119858741760254\n",
      "训练次数：200，Loss：2.2781243324279785\n",
      "time: 3.0227997303009033\n",
      "训练次数：300，Loss：2.254345178604126\n",
      "time: 3.663661003112793\n",
      "训练次数：400，Loss：2.1829824447631836\n",
      "time: 4.297572612762451\n",
      "训练次数：500，Loss：2.0739898681640625\n",
      "time: 4.915194988250732\n",
      "训练次数：600，Loss：2.0128560066223145\n",
      "time: 5.5582616329193115\n",
      "训练次数：700，Loss：2.015955924987793\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive - ahnu.edu.cn\\Vscode\\唐宇迪pytorch\\0_11_完整的训练流程.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20ahnu.edu.cn/Vscode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# 训练步骤开始\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20ahnu.edu.cn/Vscode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m module\u001b[39m.\u001b[39mtrain() \u001b[39m# 当网络中有dropout层、batchnorm层时，这些层能起作用\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20ahnu.edu.cn/Vscode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20ahnu.edu.cn/Vscode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     total_train_step \u001b[39m=\u001b[39m total_train_step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/OneDrive%20-%20ahnu.edu.cn/Vscode/%E5%94%90%E5%AE%87%E8%BF%AApytorch/0_11_%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.ipynb#W3sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     imgs, targets \u001b[39m=\u001b[39m data            \n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    556\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    558\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    559\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\cifar.py:120\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    117\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:97\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m     90\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32me:\\app\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    138\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mview(pic\u001b[39m.\u001b[39msize[\u001b[39m1\u001b[39m], pic\u001b[39m.\u001b[39msize[\u001b[39m0\u001b[39m], \u001b[39mlen\u001b[39m(pic\u001b[39m.\u001b[39mgetbands()))\n\u001b[0;32m    139\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mpermute((\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# 定义训练的设备\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda\")   # 使用 GPU 方式一 \n",
    "#device = torch.device(\"cuda:0\") # 使用 GPU 方式二\n",
    "device = torch.device(\"dml\")\n",
    "\n",
    "# from model import * 相当于把 model中的所有内容写到这里，这里直接把 model 写在这里\n",
    "class Module(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Module, self).__init__()        \n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Conv2d(3,32,5,1,2),  # 输入通道3，输出通道32，卷积核尺寸5×5，步长1，填充2    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,32,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,5,1,2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),  # 展平后变成 64*4*4 了\n",
    "            nn.Linear(64*4*4,64),\n",
    "            nn.Linear(64,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True)       \n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "# 如果train_data_size=10，则打印：训练数据集的长度为：10\n",
    "print(\"训练数据集的长度：{}\".format(train_data_size))\n",
    "print(\"测试数据集的长度：{}\".format(test_data_size))\n",
    "\n",
    "# 利用 Dataloader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)        \n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "# 创建网络模型\n",
    "module = Module() \n",
    "module = module.to(device) # 也可以不赋值，直接 tudui.to(device) \n",
    "\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵，fn 是 fuction 的缩写\n",
    "loss_fn = loss_fn.to(device) # 也可以不赋值，直接loss_fn.to(device)\n",
    "\n",
    "# 优化器\n",
    "learning = 0.01  # 1e-2 就是 0.01 的意思\n",
    "optimizer = torch.optim.SGD(module.parameters(),learning)   # 随机梯度下降优化器  \n",
    "\n",
    "# 设置网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "\n",
    "# 训练的轮次\n",
    "epoch = 3\n",
    "\n",
    "# 添加 tensorboard\n",
    "writer = SummaryWriter(\"logs\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第 {} 轮训练开始-----\".format(i+1))\n",
    "    \n",
    "    # 训练步骤开始\n",
    "    module.train() # 当网络中有dropout层、batchnorm层时，这些层能起作用\n",
    "    for data in train_dataloader:\n",
    "        total_train_step = total_train_step + 1\n",
    "\n",
    "        imgs, targets = data            \n",
    "        imgs = imgs.to(device) # 也可以不赋值，直接 imgs.to(device)\n",
    "        targets = targets.to(device) # 也可以不赋值，直接 targets.to(device)\n",
    "        outputs = module(imgs)\n",
    "        loss = loss_fn(outputs, targets) # 计算实际输出与目标输出的差距\n",
    "        \n",
    "        # 优化器对模型调优\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward() # 反向传播，计算损失函数的梯度\n",
    "        optimizer.step()   # 根据梯度，对网络的参数进行调优\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(\"time:\", end_time - start_time) # 运行训练一百次后的时间间隔\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step,loss.item()))  # 方式二：获得loss值\n",
    "            writer.add_scalar(\"train_loss\",loss.item(),total_train_step)\n",
    "    \n",
    "    # 测试步骤开始（每一轮训练后都查看在测试数据集上的loss情况）\n",
    "    module.eval()  # 当网络中有dropout层、batchnorm层时，这些层不能起作用\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():  # 没有梯度了\n",
    "        for data in test_dataloader: # 测试数据集提取数据\n",
    "            imgs, targets = data # 数据放到cuda上\n",
    "            imgs = imgs.to(device) # 也可以不赋值，直接 imgs.to(device)\n",
    "            targets = targets.to(device) # 也可以不赋值，直接 targets.to(device)\n",
    "            outputs = module(imgs)\n",
    "            loss = loss_fn(outputs, targets) # 仅data数据在网络模型上的损失\n",
    "            total_test_loss = total_test_loss + loss.item() # 所有loss\n",
    "            accuracy = (outputs.cpu().argmax(1) == targets.cpu()).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "            \n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy/test_data_size))\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss,total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\",total_accuracy/test_data_size,total_test_step)  \n",
    "    total_test_step = total_test_step + 1\n",
    "    \n",
    "    # torch.save(module, \"./dataset/module_{}.pth\".format(i)) # 保存每一轮训练后的结果\n",
    "    # torch.save(module.state_dict(),\"./dataset/module_{}.path\".format(i)) # 保存方式二         \n",
    "    # print(\"模型已保存\")\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52078a61cf360e1cb9de801769e3cf77056a7e6fc9ad1b4a4e5b78b8e2b4c3dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
