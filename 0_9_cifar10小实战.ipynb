{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d,MaxPool2d,Flatten,Linear,ReLU,Softmax\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建网路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module):\n",
    "    \"\"\"\n",
    "        输入图片shape：((n,3,32,32))\n",
    "        n为batch_size\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = Sequential(\n",
    "                Conv2d(in_channels=3,out_channels=32,kernel_size=5,\n",
    "                    stride=1,padding=2,padding_mode='zeros'), # 32,32,32\n",
    "                MaxPool2d(2, ceil_mode=True), # 32,16,16\n",
    "                Conv2d(in_channels=32,out_channels=32,kernel_size=5,\n",
    "                    stride=1,padding=2,padding_mode='zeros'), # 32,16,16,\n",
    "                MaxPool2d(2, ceil_mode=True), # 32,8,8,\n",
    "                Conv2d(in_channels=32,out_channels=64,kernel_size=5,\n",
    "                    stride=1,padding=2,padding_mode='zeros'), # 64,8,8\n",
    "                MaxPool2d(2, ceil_mode=True), # 64,4,4\n",
    "\n",
    "                Flatten(), # 1024,\n",
    "                Linear(1024,64), # 64\n",
    "                ReLU(),\n",
    "                Linear(64,10), # 10\n",
    "                Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    "module = Module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = torch.ones((64,3,32,32))\n",
    "module(data_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.ToTensor()\n",
    "test_data = datasets.CIFAR10(root='./dataset/', train=False, transform=trans, download=True )\n",
    "train_data = datasets.CIFAR10(root='./dataset/', train=True, transform=trans, download=True)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True, drop_last=False)\n",
    "n_trains = len(train_data)\n",
    "n_tests = len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练和展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\")\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.SGD(module.parameters(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 第 1 轮训练 -- \n",
      "次数: 100, loss: 2.303118944168091\n",
      "次数: 200, loss: 2.3038289546966553\n",
      "次数: 300, loss: 2.3031437397003174\n",
      "次数: 400, loss: 2.304020643234253\n",
      "次数: 500, loss: 2.301469326019287\n",
      "次数: 600, loss: 2.3010239601135254\n",
      "次数: 700, loss: 2.3013548851013184\n",
      "-- 第 1 轮训练精度: 0.1128000020980835\n",
      "-- 第 2 轮训练 -- \n",
      "次数: 800, loss: 2.302617073059082\n",
      "次数: 900, loss: 2.302574396133423\n",
      "次数: 1000, loss: 2.301694869995117\n",
      "次数: 1100, loss: 2.3005166053771973\n",
      "次数: 1200, loss: 2.30295991897583\n",
      "次数: 1300, loss: 2.3030757904052734\n",
      "次数: 1400, loss: 2.3021302223205566\n",
      "次数: 1500, loss: 2.3043904304504395\n",
      "-- 第 2 轮训练精度: 0.10970000177621841\n",
      "-- 第 3 轮训练 -- \n",
      "次数: 1600, loss: 2.3020551204681396\n",
      "次数: 1700, loss: 2.3035295009613037\n",
      "次数: 1800, loss: 2.3017964363098145\n",
      "次数: 1900, loss: 2.3038322925567627\n",
      "次数: 2000, loss: 2.3012850284576416\n",
      "次数: 2100, loss: 2.2992472648620605\n",
      "次数: 2200, loss: 2.3027095794677734\n",
      "次数: 2300, loss: 2.301649332046509\n",
      "-- 第 3 轮训练精度: 0.10840000212192535\n",
      "-- 第 4 轮训练 -- \n",
      "次数: 2400, loss: 2.3033244609832764\n"
     ]
    }
   ],
   "source": [
    "total_train_step=0\n",
    "for epoch in range(epochs):\n",
    "    print(\"-- 第 {} 轮训练 -- \".format(epoch+1))\n",
    "\n",
    "    module.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        total_train_step += 1 \n",
    "\n",
    "        imgs, targets = data\n",
    "\n",
    "        # 输出\n",
    "        out = module(imgs)\n",
    "\n",
    "        # loss\n",
    "        loss = cost(out, targets)\n",
    "        writer.add_scalar(tag=\"loss\", scalar_value=loss, global_step=total_train_step)\n",
    "        \n",
    "        # 梯度清0，反向传播，梯度step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if not total_train_step % 100:\n",
    "            print(\"次数: {0}, loss: {1}\".format(total_train_step,loss.item()))\n",
    "    \n",
    "        module.eval()\n",
    "        total_test_loss = 0\n",
    "        test_accuracy = 0\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):\n",
    "            imgs, targets = data\n",
    "            out = module(imgs)\n",
    "            total_test_loss += cost(out, targets)\n",
    "            test_accuracy += (out.argmax(1)==targets).sum()\n",
    "    test_accuracy = test_accuracy/n_tests\n",
    "    print(\"-- 第 {} 轮训练精度: {}\".format(epoch+1, test_accuracy))\n",
    "    writer.add_scalar(tag=\"total_test_loss\", scalar_value=loss, global_step=epoch+1)\n",
    "    writer.add_scalar(tag=\"test_accuracy\", scalar_value=test_accuracy, global_step=epoch+1)\n",
    "\n",
    "writer.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e88457d6133781447915b440b258f55cb00eb78ff373bb1d13c46c34b1089a25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
